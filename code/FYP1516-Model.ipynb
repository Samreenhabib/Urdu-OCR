{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57bf29da",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11272/629497118.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\RNS\\AppData\\Local\\Temp/ipykernel_11272/629497118.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38b4232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\rns\\anaconda3\\lib\\site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-21.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3168cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rns\\anaconda3\\lib\\site-packages (2.7.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (60.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rns\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4f06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc0ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"Urdu_OCR.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2685cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 9290-87CD\n",
      "\n",
      " Directory of C:\\Users\\RNS\n",
      "\n",
      "06/01/2022  08:33           783,932 Urdu_OCR.model\n",
      "               1 File(s)        783,932 bytes\n",
      "               0 Dir(s)  35,324,055,552 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls Urdu_OCR.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56e15e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001AD383822B0>\n"
     ]
    }
   ],
   "source": [
    "print(reconstructed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efa04cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Left 6/6.Done with 6 images!\n",
      "Images Left 6/6.Done with 6 images!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pdb\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "\n",
    "INPUT_DIR=\"test\"\n",
    "IMG_SIZE=50\n",
    "X=[]\n",
    "LIST_IMG=[]\n",
    "counter=1\n",
    "\n",
    "for image in os.listdir(INPUT_DIR):\n",
    "        img = cv2.imread(os.path.join(INPUT_DIR,image),cv2.IMREAD_GRAYSCALE)\n",
    "        _,img=cv2.threshold(img,200,255,cv2.THRESH_BINARY)\n",
    "        # Saving the result.\n",
    "        LIST_IMG.append(img)\n",
    "        # Printing the result so far.\n",
    "        sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(os.listdir(INPUT_DIR))))\n",
    "        sys.stdout.flush()\n",
    "        # Incrementing the counter\n",
    "        counter = counter + 1\n",
    "\n",
    "print(\"Done with {} images!\".format(counter-1))\n",
    "\n",
    "counter=1\n",
    "    \n",
    "for image in LIST_IMG:\n",
    "    image= cv2.copyMakeBorder(image, 10, 10, 10, 10, borderType=cv2.BORDER_CONSTANT, value=255)\n",
    "        # Changing datatype of the image for resizing..\n",
    "    image=image.astype(np.uint8)\n",
    "        # Resizing the image.\n",
    "    img_resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        # Appending the image and the class number to the main list..\n",
    "    X.append(img_resized)\n",
    "       # Printing the result so far.\n",
    "    sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(LIST_IMG)))\n",
    "    sys.stdout.flush()\n",
    "       # Incrementing the counter\n",
    "    counter = counter + 1\n",
    "\n",
    "print(\"Done with {} images!\".format(counter - 1))\n",
    "\n",
    "input_data = np.asarray(X)\n",
    "my_model = tf.keras.models.load_model(\"Urdu_OCR.model\")\n",
    "\n",
    "    # Making predictions..\n",
    "predictions = my_model.predict(input_data)\n",
    "\n",
    "    # Opening a text file..\n",
    "filename = \"Digitized Text.txt\"\n",
    "file = codecs.open(filename, \"w\", \"utf8\")\n",
    "\n",
    "CATEGORIES = ['Alif', \"Alifmada'a\", 'Bariyay', 'Bhi', 'choti yay', 'Daal', 'Dash', 'Golhay', 'Hai', 'Hain',\n",
    "                  'Hou', 'jou', 'Ka', 'Kar', 'Kay', 'Keh', 'Ki', 'Kou', 'La', 'meem', 'Mein', 'N', 'Nay', 'noonguna',\n",
    "                  'Raay', 'say', 'seen', 'tay', 'tou', 'Wow', 'Ya']\n",
    "\n",
    "    # Mapping predictions with their correct labels and writing to file..\n",
    "for p in predictions:\n",
    "    index = np.argmax(p)\n",
    "    confidence = np.max(p)\n",
    "    predicted_lig = CATEGORIES[index]\n",
    "        # Now considering the different cases...\n",
    "        # If the confidence is greater than a certain threshold...\n",
    "    if confidence >= 0.9:\n",
    "        if predicted_lig == \"Alif\":\n",
    "            file.write(\"ا \")\n",
    "        elif predicted_lig == \"Alifmada'a\":\n",
    "            file.write(\"آ \")\n",
    "        elif predicted_lig == \"Bariyay\":\n",
    "            file.write(\"ے \")\n",
    "        elif predicted_lig == \"Bhi\":\n",
    "            file.write(\"بھی \")\n",
    "        elif predicted_lig == \"choti yay\":\n",
    "            file.write(\"ی \")\n",
    "        elif predicted_lig == \"Daal\":\n",
    "            file.write(\"د \")\n",
    "        elif predicted_lig == \"Dash\":\n",
    "            file.write(\"۔ \")\n",
    "        elif predicted_lig == \"Golhay\":\n",
    "            file.write(\"ہ \")\n",
    "        elif predicted_lig == \"Hai\":\n",
    "            file.write(\"ہے \")\n",
    "        elif predicted_lig == \"Hain\":\n",
    "            file.write(\"ہیں \")\n",
    "        elif predicted_lig == \"Hou\":\n",
    "            file.write(\"ہو \")\n",
    "        elif predicted_lig == \"jou\":\n",
    "            file.write(\"جو \")\n",
    "        elif predicted_lig == \"Ka\":\n",
    "            file.write(\"کا \")\n",
    "        elif predicted_lig == \"Kar\":\n",
    "            file.write(\"کر \")\n",
    "        elif predicted_lig == \"Kay\":\n",
    "            file.write(\"کے \")\n",
    "        elif predicted_lig == \"Keh\":\n",
    "            file.write(\"کہ \")\n",
    "        elif predicted_lig == \"Ki\":\n",
    "            file.write(\"کی \")\n",
    "        elif predicted_lig == \"Kou\":\n",
    "            file.write(\"کو \")\n",
    "        elif predicted_lig == \"La\":\n",
    "            file.write(\"لا \")\n",
    "        elif predicted_lig == \"meem\":\n",
    "            file.write(\"م \")\n",
    "        elif predicted_lig == \"Mein\":\n",
    "            file.write(\"میں \")\n",
    "        elif predicted_lig == \"N\":\n",
    "            file.write(\"ن \")\n",
    "        elif predicted_lig == \"Nay\":\n",
    "            file.write(\"نے \")\n",
    "        elif predicted_lig == \"noonguna\":\n",
    "            file.write(\"ں \")\n",
    "        elif predicted_lig == \"Raay\":\n",
    "            file.write(\"ر \")\n",
    "        elif predicted_lig == \"say\":\n",
    "            file.write(\"سے \")\n",
    "        elif predicted_lig == \"seen\":\n",
    "            file.write(\"س \")\n",
    "        elif predicted_lig == \"tay\":\n",
    "            file.write(\"ت \")\n",
    "        elif predicted_lig == \"tou\":\n",
    "            file.write(\"تا \")\n",
    "        elif predicted_lig == \"Wow\":\n",
    "            file.write(\"و \")\n",
    "        elif predicted_lig == \"Ya\":\n",
    "            file.write(\"یا \")\n",
    "    else:\n",
    "        file.write(\"٭\")\n",
    "    # Closing the file.\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da39482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIPTION:\n",
    "# The training images are thresholded to remove any backgrounf noise here.\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pdb\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "\n",
    "# Line Splitting Function....\n",
    "def line_splitter(input_image):\n",
    "    # Main list to store the output ligatures i.e. a list of numpy arrays.\n",
    "    out_image_array=[]\n",
    "\n",
    "    # Variable for storing the total number of lines.\n",
    "    total_lines = 0\n",
    "\n",
    "    # Extracting the dimensions of the image\n",
    "    height,width=input_image.shape\n",
    "\n",
    "    # Making a bool type filter\n",
    "    filter=np.ones(shape=(1,width),dtype=bool)\n",
    "\n",
    "    # Converting the source image to bool.\n",
    "    input_image=input_image.astype(bool)\n",
    "\n",
    "\n",
    "    # Some workplace variables for the following for loop.\n",
    "    row=0   #This variable indexs the pixels of the image row wise.\n",
    "    first_row=True\n",
    "    line_detected=False\n",
    "\n",
    "    # This for loop iterates through each pixel wide line of the page and separates them.\n",
    "    for i in input_image:\n",
    "        i=np.reshape(i,newshape=(1,width))\n",
    "        res=np.bitwise_and(i,filter)\n",
    "        res=np.bitwise_and.reduce(res,axis=1)\n",
    "\n",
    "        if res==False:\n",
    "            line_detected=True\n",
    "            if first_row==True:\n",
    "                row_start=row\n",
    "                first_row=False\n",
    "            row = row + 1\n",
    "            continue\n",
    "\n",
    "        if line_detected==True:\n",
    "            row_end=row\n",
    "            line_detected=False\n",
    "            first_row = True\n",
    "            out_image=input_image[row_start:row_end,:]\n",
    "            out_image=out_image.astype(int)  #Converting back to int.\n",
    "            out_image=out_image*255          #Replacing the 1's by 255's.\n",
    "            # Writing the output.\n",
    "            out_image_array.append(out_image)\n",
    "            total_lines=total_lines+1\n",
    "        row = row + 1\n",
    "    # print(\"Lines separated successfully. Total lines {}.\".format(total_lines))\n",
    "    # Returning the list..\n",
    "    return out_image_array\n",
    "# Ligature Splitting Function....\n",
    "def splitter(input_image):\n",
    "    # Main list to store the output ligatures i.e. a list of numpy arrays.\n",
    "    out_image_array = []\n",
    "    # Variable for storing the total number of ligatures.\n",
    "    total_ligatures = 0\n",
    "\n",
    "    # Flipping the image counter clockwise.\n",
    "    input_image = cv2.transpose(input_image)\n",
    "    input_image = cv2.flip(input_image, flipCode=0)\n",
    "\n",
    "    # Extracting the dimensions of the image\n",
    "    height, width = input_image.shape\n",
    "\n",
    "    # Making a bool type filter\n",
    "    filter = np.ones(shape=(1, width), dtype=bool)\n",
    "\n",
    "    # Converting the source image to bool.\n",
    "    input_image = input_image.astype(bool)\n",
    "\n",
    "    # Some workplace variables for the following for loop.\n",
    "    row = 0  # This variable indexs the pixels of the image row wise.\n",
    "    first_row = True\n",
    "    ligature_detected = False\n",
    "\n",
    "    # This for loop iterates through each pixel wide line of the line and separates the ligatures.\n",
    "    for i in input_image:\n",
    "        i = np.reshape(i, newshape=(1, width))\n",
    "        # Applying the operation of the filter with the row.\n",
    "        res = np.bitwise_and(i, filter)\n",
    "        # Reducing the result.\n",
    "        res = np.bitwise_and.reduce(res, axis=1)\n",
    "\n",
    "        if res == False:\n",
    "            ligature_detected = True\n",
    "            if first_row == True:\n",
    "                row_start = row\n",
    "                first_row = False\n",
    "            row = row + 1\n",
    "            continue\n",
    "\n",
    "        if ligature_detected == True:\n",
    "            row_end = row\n",
    "            ligature_detected = False\n",
    "            first_row = True\n",
    "            out_image = input_image[row_start:row_end, :]  # Cropping the image.\n",
    "            out_image = out_image.astype(int)  # Converting back to int.\n",
    "            out_image = out_image * 255  # Replacing the 1's by 255's\n",
    "            # Flipping the output image back in clockwise direction.\n",
    "            out_image = cv2.transpose(out_image)\n",
    "            out_image = cv2.flip(out_image, flipCode=+1)\n",
    "            # Writing the output to the array\n",
    "            out_image_array.append(out_image)\n",
    "            total_ligatures = total_ligatures + 1\n",
    "\n",
    "        row = row + 1\n",
    "    # print(\"Ligatures separated successfully. Total ligatures {}.\".format(total_ligatures))\n",
    "    # Returning the list..\n",
    "    return out_image_array\n",
    "#Function for performing the task of steretching..\n",
    "def stretcher(input_image,degree_of_stretch):\n",
    "    # Getting the dimensions\n",
    "    height_original, width_original = input_image.shape\n",
    "\n",
    "    # Making the height of the image divisible by degree_of_stretch\n",
    "    while(height_original%degree_of_stretch!=0):\n",
    "        height_original=height_original+1\n",
    "        input_image=np.insert(input_image,0,255,0)\n",
    "\n",
    "\n",
    "    # degree_of_stretch:\n",
    "    # How many pixels to skip for the shifting operation.\n",
    "    # OR we can say that it is the degree of stretch.\n",
    "    final_width = width_original + int(height_original / degree_of_stretch)\n",
    "    img_modified = np.ones((height_original, final_width))\n",
    "    img_modified=img_modified*255\n",
    "    counter = 0\n",
    "    inserts = 0    #paddings\n",
    "    for row in img_modified:\n",
    "        if counter % degree_of_stretch == 0:\n",
    "            inserts = inserts + 1\n",
    "        row[0 + inserts: width_original + inserts] = input_image[counter] #  row[2:22] replace by input_image[1]\n",
    "        counter = counter + 1\n",
    "    return img_modified\n",
    "# Function for reversing the task of steretching..\n",
    "def deStretcher(input_image,degree_of_stretch):\n",
    "    # Getting the dimensions\n",
    "    height_original, width_original = input_image.shape\n",
    "\n",
    "    # degree_of_stretch:\n",
    "    # How to many pixels to skip for the shifting operation.\n",
    "    # OR we can say that it is the degree of stretch.\n",
    "\n",
    "    # # Making the height of the image divisible by degree_of_stretch\n",
    "    # while (height_original % degree_of_stretch != 0):\n",
    "    #     height_original = height_original + 1\n",
    "    #     original_image = np.insert(original_image, 0, 255, 0)\n",
    "\n",
    "    final_width = width_original + int(height_original/ degree_of_stretch)\n",
    "    img_modified = np.ones((height_original, final_width))\n",
    "    img_modified = img_modified * 255\n",
    "    counter = 0\n",
    "    inserts = 0\n",
    "    for row in img_modified:\n",
    "        if counter % degree_of_stretch == 0:\n",
    "            inserts = inserts + 1\n",
    "        row[final_width - width_original - inserts:final_width - inserts] = input_image[counter]\n",
    "        counter = counter + 1\n",
    "\n",
    "    # Returning the result..\n",
    "    return img_modified\n",
    "# The main function for carrying out the fitting task.\n",
    "def fitter(input_image):\n",
    "    # Extracting the dimensions of the image\n",
    "    height, width = input_image.shape\n",
    "\n",
    "    # Making a bool type filter\n",
    "    filter = np.ones(shape=(1, width), dtype=bool)\n",
    "\n",
    "    # Converting the source image to bool.\n",
    "    input_image = input_image.astype(bool)\n",
    "    # Some workplace variables for the following for loop.\n",
    "    row = 0  # This variable indexs the pixels of the image row wisE FROM THE TOP.\n",
    "    # This for loop iterates through each pixel wide line of the page and separates them.\n",
    "    # First we start from the top of the image\n",
    "    for i in input_image:\n",
    "        i = np.reshape(i, newshape=(1, width))\n",
    "        res = np.bitwise_and(i, filter)\n",
    "        res = np.bitwise_and.reduce(res, axis=1)\n",
    "        if res == False:\n",
    "            row_start = row\n",
    "            break\n",
    "        row = row + 1\n",
    "        continue\n",
    "\n",
    "    # Flipping the image horizontally.\n",
    "    input_image = input_image.astype(int)  # Converting back to int.\n",
    "    input_image = input_image * 255  # Replacing the 1's by 255's.\n",
    "    input_image = cv2.flip(src=input_image, flipCode=0)\n",
    "    input_image = input_image.astype(bool)  # Converting back to bool after flipping.\n",
    "\n",
    "    row = 0  # This variable indexs the pixels of the image row wisE FROM THE BOTTOM.\n",
    "    # Then we apply the same algorithm on the inverted image.\n",
    "    for i in input_image:\n",
    "        i = np.reshape(i, newshape=(1, width))\n",
    "        res = np.bitwise_and(i, filter)\n",
    "        res = np.bitwise_and.reduce(res, axis=1)\n",
    "        if res == False:\n",
    "            row_end = height - row\n",
    "            break\n",
    "        row = row + 1\n",
    "        continue\n",
    "\n",
    "    # Flipping the image back.\n",
    "    input_image = input_image.astype(int)  # Converting back to int.\n",
    "    input_image = input_image * 255  # Replacing the 1's by 255's.\n",
    "    input_image = cv2.flip(src=input_image, flipCode=0)\n",
    "\n",
    "    # Cutting the image coordinates.\n",
    "    out_image = input_image[row_start:row_end, :]\n",
    "\n",
    "    # Returning the numpy array.\n",
    "    return out_image\n",
    "\n",
    "\n",
    "def main():\n",
    "    IMDIR=\"test\"\n",
    "    # OUTDIR=\"E:\\\\NED\\\\FYP\\\\Final FYP\\\\Image Processing Part\\\\testing\"\n",
    "    # if not os.path.isdir(OUTDIR):\n",
    "    #     os.mkdir(OUTDIR)\n",
    "\n",
    "\n",
    "    # ////////////////////////////////////////////////THRESHOLDING////////////////////////////////////////////////\n",
    "    print(\"\\nPerforming Image Preprocessing...\\n\")\n",
    "    # A list to store the thresholded images..\n",
    "    THREHOLDED_IMAGES=[]\n",
    "    counter=1\n",
    "    for image in os.listdir(IMDIR):\n",
    "        img = cv2.imread(os.path.join(IMDIR,image),cv2.IMREAD_GRAYSCALE)\n",
    "        _,img=cv2.threshold(img,200,255,cv2.THRESH_BINARY)\n",
    "        # Saving the result.\n",
    "        THREHOLDED_IMAGES.append(img)\n",
    "        # Printing the result so far.\n",
    "        sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(os.listdir(IMDIR))))\n",
    "        sys.stdout.flush()\n",
    "        # Incrementing the counter\n",
    "        counter = counter + 1\n",
    "    print(\"Done with {} images!\".format(counter-1))\n",
    "\n",
    "    # ////////////////////////////////////////////////LINE SPLITTING////////////////////////////////////////////////\n",
    "    print(\"\\nPerforming Line Segmentation...\\n\")\n",
    "    # list to store the results.\n",
    "    LIST_OF_LINES= []\n",
    "    # Making a counter to keep track of the images.\n",
    "    counter = 1\n",
    "    # The main for loop iterating through each image.\n",
    "    for image in THREHOLDED_IMAGES:\n",
    "        # Applying the line splitter function..\n",
    "        lines=line_splitter(image)\n",
    "        # Appending the lines to the main list..\n",
    "        for l in lines:\n",
    "            LIST_OF_LINES.append(l)\n",
    "        # Printing the result so far.\n",
    "        sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(THREHOLDED_IMAGES)))\n",
    "        sys.stdout.flush()\n",
    "        # Incrementing the counter\n",
    "        counter = counter + 1\n",
    "    print(\"Done with {} images!\".format(counter-1))\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\nPerforming Ligature Segmentation...\\n\")\n",
    "    # The function returns a list of ligatures. Making that list:\n",
    "    LIST_OF_LIGATURES = []\n",
    "    # This increments for each ligature image separated\n",
    "    counter = 1\n",
    "    # Main for loop iterating through the images.\n",
    "    for image in LIST_OF_LINES:\n",
    "        # Performing the ligature splitting...\n",
    "        ligatures = splitter(image)\n",
    "        for l in ligatures:\n",
    "            LIST_OF_LIGATURES.append(l)\n",
    "        # Printing the result so far.\n",
    "        sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(LIST_OF_LINES)))\n",
    "        sys.stdout.flush()\n",
    "        # Incrementing the counter\n",
    "        counter = counter + 1\n",
    "    print(\"Done with {} images!\".format(counter - 1))\n",
    "\n",
    "  \n",
    "    print(\"\\nPerforming Advanced Ligature Segmentation...\\n\")\n",
    "    # The function returns a list of ligatures. Making that list:\n",
    "    LIST_OF_LIGATURES_ADVANCED = []\n",
    "    # Some important angle values\n",
    "    degree_of_stretcher = 2\n",
    "    # This increments for each ligature image separated\n",
    "    counter = 1\n",
    "    # Main for loop iterating through the images.\n",
    "    for image in LIST_OF_LIGATURES:\n",
    "        # Rotating the image\n",
    "        img_rotated = stretcher(image, degree_of_stretcher)\n",
    "        # Now applying the ligature segmentation on the rotated images.\n",
    "        ligatures = splitter(img_rotated)\n",
    "        # Rotating the segmented ligatures back to the original angles.\n",
    "        for lig in ligatures:\n",
    "            # Rotating back...\n",
    "            lig = deStretcher(lig, degree_of_stretcher)\n",
    "            # Fittting the ligatures\n",
    "            lig = fitter(lig)\n",
    "            lig = cv2.transpose(lig)\n",
    "            lig = fitter(lig)\n",
    "            lig = cv2.transpose(lig)\n",
    "            # Saving the liagtures in the main list...\n",
    "            LIST_OF_LIGATURES_ADVANCED.append(lig)\n",
    "            # Printing the result so far.\n",
    "        sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(LIST_OF_LIGATURES)))\n",
    "        sys.stdout.flush()\n",
    "        # Incrementing the counter\n",
    "        counter = counter + 1\n",
    "    print(\"Done with {} images!\".format(counter - 1))\n",
    "\n",
    "    # ////////////////////////////////////////////////PREPROCESSING FOR NEURAL NET////////\n",
    "    print(\"\\nPreprocessng The Data for Classification...\\n\")\n",
    "    # Output image size.\n",
    "    IMG_SIZE = 50\n",
    "    # List of all the data..\n",
    "    X = []\n",
    "    # This increments for each ligature image separated\n",
    "    counter = 1\n",
    "    # Main for loop iterating through the images.\n",
    "    for image in LIST_OF_LIGATURES_ADVANCED:\n",
    "        # Adding some padding to the image.\n",
    "        image= cv2.copyMakeBorder(image, 10, 10, 10, 10, borderType=cv2.BORDER_CONSTANT, value=255)\n",
    "        # Changing datatype of the image for resizing..\n",
    "        image=image.astype(np.uint8)\n",
    "        # Resizing the image.\n",
    "        img_resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        # Appending the image and the class number to the main list..\n",
    "        X.append(img_resized)\n",
    "        # Printing the result so far.\n",
    "        sys.stdout.write(\"\\rImages Left {}/{}.\".format(counter, len(LIST_OF_LIGATURES_ADVANCED)))\n",
    "        sys.stdout.flush()\n",
    "        # Incrementing the counter\n",
    "        counter = counter + 1\n",
    "    print(\"Done with {} images!\".format(counter - 1))\n",
    "\n",
    "\n",
    "    print(\"\\nUndergoing Classification and Making Final Document...\\n\")\n",
    "    # The main categories\n",
    "    CATEGORIES = ['Alif', \"Alifmada'a\", 'Bariyay', 'Bhi', 'choti yay', 'Daal', 'Dash', 'Golhay', 'Hai', 'Hain',\n",
    "                  'Hou', 'jou', 'Ka', 'Kar', 'Kay', 'Keh', 'Ki', 'Kou', 'La', 'meem', 'Mein', 'N', 'Nay', 'noonguna',\n",
    "                  'Raay', 'say', 'seen', 'tay', 'tou', 'Wow', 'Ya']\n",
    "\n",
    "    # Loading the input data and converting to numpy..\n",
    "    input_data = np.asarray(X)\n",
    "\n",
    "    # Loading the saved model\n",
    "    my_model = tf.keras.models.load_model(\"Urdu_OCR.model\")\n",
    "\n",
    "    # Making predictions..\n",
    "    predictions = my_model.predict(input_data)\n",
    "\n",
    "    # Opening a text file..\n",
    "    filename = \"Digitized Text.txt\"\n",
    "    file = codecs.open(filename, \"w\", \"utf8\")\n",
    "\n",
    "    # Mapping predictions with their correct labels and writing to file..\n",
    "    for p in predictions:\n",
    "        index = np.argmax(p)\n",
    "        confidence = np.max(p)\n",
    "        predicted_lig = CATEGORIES[index]\n",
    "        # Now considering the different cases...\n",
    "        # If the confidence is greater than a certain threshold...\n",
    "        if confidence >= 0.9:\n",
    "            if predicted_lig == \"Alif\":\n",
    "                file.write(\"ا \")\n",
    "            elif predicted_lig == \"Alifmada'a\":\n",
    "                file.write(\"آ \")\n",
    "            elif predicted_lig == \"Bariyay\":\n",
    "                file.write(\"ے \")\n",
    "            elif predicted_lig == \"Bhi\":\n",
    "                file.write(\"بھی \")\n",
    "            elif predicted_lig == \"choti yay\":\n",
    "                file.write(\"ی \")\n",
    "            elif predicted_lig == \"Daal\":\n",
    "                file.write(\"د \")\n",
    "            elif predicted_lig == \"Dash\":\n",
    "                file.write(\"۔ \")\n",
    "            elif predicted_lig == \"Golhay\":\n",
    "                file.write(\"ہ \")\n",
    "            elif predicted_lig == \"Hai\":\n",
    "                file.write(\"ہے \")\n",
    "            elif predicted_lig == \"Hain\":\n",
    "                file.write(\"ہیں \")\n",
    "            elif predicted_lig == \"Hou\":\n",
    "                file.write(\"ہو \")\n",
    "            elif predicted_lig == \"jou\":\n",
    "                file.write(\"جو \")\n",
    "            elif predicted_lig == \"Ka\":\n",
    "                file.write(\"کا \")\n",
    "            elif predicted_lig == \"Kar\":\n",
    "                file.write(\"کر \")\n",
    "            elif predicted_lig == \"Kay\":\n",
    "                file.write(\"کے \")\n",
    "            elif predicted_lig == \"Keh\":\n",
    "                file.write(\"کہ \")\n",
    "            elif predicted_lig == \"Ki\":\n",
    "                file.write(\"کی \")\n",
    "            elif predicted_lig == \"Kou\":\n",
    "                file.write(\"کو \")\n",
    "            elif predicted_lig == \"La\":\n",
    "                file.write(\"لا \")\n",
    "            elif predicted_lig == \"meem\":\n",
    "                file.write(\"م \")\n",
    "            elif predicted_lig == \"Mein\":\n",
    "                file.write(\"میں \")\n",
    "            elif predicted_lig == \"N\":\n",
    "                file.write(\"ن \")\n",
    "            elif predicted_lig == \"Nay\":\n",
    "                file.write(\"نے \")\n",
    "            elif predicted_lig == \"noonguna\":\n",
    "                file.write(\"ں \")\n",
    "            elif predicted_lig == \"Raay\":\n",
    "                file.write(\"ر \")\n",
    "            elif predicted_lig == \"say\":\n",
    "                file.write(\"سے \")\n",
    "            elif predicted_lig == \"seen\":\n",
    "                file.write(\"س \")\n",
    "            elif predicted_lig == \"tay\":\n",
    "                file.write(\"ت \")\n",
    "            elif predicted_lig == \"tou\":\n",
    "                file.write(\"تا \")\n",
    "            elif predicted_lig == \"Wow\":\n",
    "                file.write(\"و \")\n",
    "            elif predicted_lig == \"Ya\":\n",
    "                file.write(\"یا \")\n",
    "        else:\n",
    "            file.write(\"٭\")\n",
    "    # Closing the file.\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39caa73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Image Preprocessing...\n",
      "\n",
      "Images Left 1/1.Done with 1 images!\n",
      "\n",
      "Performing Line Segmentation...\n",
      "\n",
      "Images Left 1/1.Done with 1 images!\n",
      "\n",
      "Performing Ligature Segmentation...\n",
      "\n",
      "Images Left 10/10.Done with 10 images!\n",
      "\n",
      "Performing Advanced Ligature Segmentation...\n",
      "\n",
      "Images Left 99/99.Done with 99 images!\n",
      "\n",
      "Preprocessng The Data for Classification...\n",
      "\n",
      "Images Left 126/126.Done with 126 images!\n",
      "\n",
      "Undergoing Classification and Making Final Document...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e0c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
