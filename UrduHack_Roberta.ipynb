{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UrduHack-Roberta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3LPfjWPfrXb"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel\n",
        "\n",
        "# initialize the encoder from a pretrained ViT and the decoder from a pretrained BERT model. \n",
        "# Note that the cross-attention layers will be randomly initialized, and need to be fine-tuned on a downstream dataset\n",
        "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\", \"urduhack/roberta-urdu-small\"\n",
        ")\n",
        "# set decoder config to causal lm\n",
        "model.config.decoder.is_decoder = True\n",
        "model.config.decoder.add_cross_attention = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYX2OOp1hKiX",
        "outputId": "e0925a27-516b-45ef-cfe2-687d0e9295fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at urduhack/roberta-urdu-small and are newly initialized: ['roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "img = Image.open('15.png').convert(\"RGB\")"
      ],
      "metadata": {
        "id": "0tz4BFg5heH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, AutoTokenizer"
      ],
      "metadata": {
        "id": "U5TguRTDiMpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "decoder_tokenizer = AutoTokenizer.from_pretrained(\"urduhack/roberta-urdu-small\")"
      ],
      "metadata": {
        "id": "0xvM4qoHiRnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values = feature_extractor(images=img, return_tensors=\"pt\").pixel_values  # Batch size 1\n",
        "#decoder_input_ids = decoder_tokenizer(\"Linda Davis\", return_tensors=\"tf\").input_ids  # Batch size 1\n",
        "#outputs = model(pixel_values=pixel_values, decoder_input_ids=decoder_input_ids)\n",
        "# generation\n",
        "generated = model.generate(pixel_values)"
      ],
      "metadata": {
        "id": "yUpG4VnvibGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE8X42t7jBAE",
        "outputId": "c117044b-2781-40be-f30e-3ff5fd8d2e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0,  322, 2992, 2992, 2992, 2992, 2992, 2992, 2992, 2992, 2992, 2992,\n",
            "         2992, 2992, 2992, 2992, 2992, 2992, 2992, 2992]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = decoder_tokenizer.batch_decode(generated, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "nxltt9zhjD1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz0X0WHwjTlb",
        "outputId": "8a885dc6-9d9b-4553-b3fd-b80d66f966f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " کوکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسیکسی\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_tokenizer.save_pretrained(\"roberta\")"
      ],
      "metadata": {
        "id": "NQ2njpBtlyny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8928bed-b6ba-4437-e8ca-4fc2f94ce37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('roberta/tokenizer_config.json',\n",
              " 'roberta/special_tokens_map.json',\n",
              " 'roberta/vocab.json',\n",
              " 'roberta/merges.txt',\n",
              " 'roberta/added_tokens.json',\n",
              " 'roberta/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "GMBawk0Vpw4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_tokenizer.save_pretrained(\"berta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5rkj162q6PG",
        "outputId": "64141223-ef95-4c83-d604-c64c7076a83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('berta/tokenizer_config.json',\n",
              " 'berta/special_tokens_map.json',\n",
              " 'berta/vocab.txt',\n",
              " 'berta/added_tokens.json',\n",
              " 'berta/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}