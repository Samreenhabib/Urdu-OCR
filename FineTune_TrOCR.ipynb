{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTune TrOCR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5NOmIyIeNC2"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "id": "1Af4sCb2NKqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets jiwer"
      ],
      "metadata": {
        "id": "D5sGBVrOfOCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2"
      ],
      "metadata": {
        "id": "8Pn1cGrcfXKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/test.xlsx', header=None)\n",
        "df.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\n",
        "df['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbQOG0wsgNR9",
        "outputId": "4d2ef481-ca3b-46f8-d1df-f025ebfa770a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ایک پاکستانی نوجوان کی داستان\n",
              "1                    ہی کا کمال ہے\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del df[2]\n",
        "# some file names end with jp instead of jpg, let's fix this\n",
        "df['file_name'] = df['file_name'].apply(lambda x: x + 'g' if x.endswith('pn') else x)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "K3AHMmkzgKVq",
        "outputId": "069cb37a-ce3f-4328-a39c-d33dda384d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a8a12d4-a809-40f1-89fa-203ba0905aa6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.png</td>\n",
              "      <td>ایک پاکستانی نوجوان کی داستان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.png</td>\n",
              "      <td>ہی کا کمال ہے</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a8a12d4-a809-40f1-89fa-203ba0905aa6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a8a12d4-a809-40f1-89fa-203ba0905aa6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a8a12d4-a809-40f1-89fa-203ba0905aa6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  file_name                           text\n",
              "0     6.png  ایک پاکستانی نوجوان کی داستان\n",
              "1    40.png                  ہی کا کمال ہے"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.1)\n",
        "# we reset the indices to start from zero\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "zApHMdXME_fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ATlXnkStKP4h",
        "outputId": "13269638-a6bc-44bd-bbce-c786474e22a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f923960a-9e0f-45b6-9ade-b3f570e39ce0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.png</td>\n",
              "      <td>ہی کا کمال ہے</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f923960a-9e0f-45b6-9ade-b3f570e39ce0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f923960a-9e0f-45b6-9ade-b3f570e39ce0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f923960a-9e0f-45b6-9ade-b3f570e39ce0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  file_name           text\n",
              "0    40.png  ہی کا کمال ہے"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "tS5YD3N-LiX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IAMDataset(Dataset):\n",
        "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get file name + text \n",
        "        file_name = self.df['file_name'][idx]\n",
        "        text = self.df['text'][idx]\n",
        "        # prepare image (i.e. resize + normalize)\n",
        "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
        "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
        "        # add labels (input_ids) by encoding the text\n",
        "        labels = self.processor.tokenizer(text, \n",
        "                                          padding=\"max_length\", \n",
        "                                          max_length=self.max_target_length).input_ids\n",
        "        # important: make sure that PAD tokens are ignored by the loss function\n",
        "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "pxTuvu9eMI3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
        "train_dataset = IAMDataset(root_dir='/content/image/',\n",
        "                           df=train_df,\n",
        "                           processor=processor)\n",
        "\n",
        "eval_dataset = IAMDataset(root_dir='/content/image/',\n",
        "                           df=test_df,\n",
        "                           processor=processor)"
      ],
      "metadata": {
        "id": "sq00z7RAM2M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "EcI9agCyNW1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training examples:\", len(train_dataset))\n",
        "print(\"Number of training examples:\", len(eval_dataset))"
      ],
      "metadata": {
        "id": "Txfxo-KRNZz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = train_dataset[0]\n",
        "for k,v in encoding.items():\n",
        "  print(k, v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0concBRNq3Y",
        "outputId": "8838b145-bf81-408c-e9eb-2ea5ae8e5243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_values torch.Size([3, 384, 384])\n",
            "labels torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(train_dataset.root_dir + train_df['file_name'][0]).convert(\"RGB\")\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hHAqUxYtOFTJ",
        "outputId": "6646a973-5a92-4459-ec7f-b01ccffc6de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABOUAAAArCAIAAAC4kKsHAAADQUlEQVR4nO3dzW6jMBSA0TLq+78ys6iEUCBgsA33wjmrjNq6Tlb9xj8M4zj+AAAAlBmGQURwjX93TwAAAEhjGIZ+I/cbnKR+754AAADwalOmWrblg/VVAADgHvM11aOxajH2DayvAgAARRom4sdQYpVVehUAALhOZalOI9g8/AZ6FQAAuEJ9qS4H4dn0KgAA0N28M08vjbqZ6W3ctwQAANQqXPYcx3E7NTfGEasvZH0VAACoshurhSdOv41TuTa7HFbxZmF9FQAAiKt5rJKIXgUAAIrU3JBUf7uSWH0h+4EBAID7LbO28sDq8sc9CCcdvQoAAITTPFZPD8WN7AcGAABiaXUVsEDNTq8CAACBlMfq6eOpzrVmoVcBACCfYRj+omt68TA1sbr9gTzy43oqvQoAAMlMxfW89Jq/td13V9K0q4PYJ5yFXgUAgEyaN2rk6G0yt/kgkd8sS3oVAABymFYLP5YHa1YL4/fb6gxrpm1xNRG9CgAA0c33tf7l1jiO04vKwa/ptyvDePmOprO+l82BJvQqAADE9XECs+HK6vVOXw3VtjOfekPVI/3ePQEAAGDdRqk2H7/coZmc+BXT+Ns/uz2Nv6/q0uysrwIAQETzDcC51lEnNbE6f/3x9suHbbhrmlvoVQAACGe6VylUaB3qz4APkvkWwISlVwEAIJaku1h3HxtTUom9n9YT7b8A2Ob8KgAAdFQYYKsR1fv86iGrj9JZ/Z65E9NeFua3b7v9M6E3vQoAAIF869tWC4/nGu+Cm5l6KGlsIrMfGAAAOiqJpcuCancVd9XHo19rflfD79+VdFs1c9ZXAQCgr3mJ7e6YHcexR2idrsGSyXSa80/B9uP4+6ipYc83AACE0yT/dv/U3zgpeuIkapNKLBzk28ybHKAlDr0KAAAvdehBpl1nclTNLVYk4vwqAAC8VGHOJa2+pNNmTq8CAEAmF18jFLP6dmcVc9ocpVcBACCN5rG63XWRq29jbpGnzSHOrwIAQBrfbsRtMvL8n1kyIem0KaRXAQAgh7828wc872E/MAAAABHpVQAASMPiKq9iPzAAACTgoCYvZH0VAACAiPQqAAAkYEGVF9KrAACQjHblJf4DAu5ojTLwPZ8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=1253x43 at 0x7FB3D2C5B950>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = encoding['labels']\n",
        "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
        "label_str = processor.decode(labels, skip_special_tokens=True)\n",
        "print(label_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4FgF2ILOLy_",
        "outputId": "9889af46-4f91-41d9-e351-8f331abc46bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ہی کا کمال ہے\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    \"google/vit-base-patch16-384\", \"urduhack/roberta-urdu-small\"\n",
        ")\n",
        "# set decoder config to causal lm\n",
        "model.config.decoder.is_decoder = True\n",
        "model.config.decoder.add_cross_attention = True"
      ],
      "metadata": {
        "id": "xgJGlP_rORnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set special tokens used for creating the decoder_input_ids from the labels\n",
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "# make sure vocab size is set correctly\n",
        "model.config.vocab_size = model.config.decoder.vocab_size\n",
        "\n",
        "# set beam search parameters\n",
        "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
        "model.config.max_length = 64\n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 4"
      ],
      "metadata": {
        "id": "W0BCpPCGQkDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    fp16=True, \n",
        "    output_dir=\"./\",\n",
        "    logging_steps=2,\n",
        "    save_steps=1000,\n",
        "    eval_steps=200,\n",
        ")"
      ],
      "metadata": {
        "id": "EkkIFGm3TPn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "cer_metric = load_metric(\"cer\")"
      ],
      "metadata": {
        "id": "9lFXbLMkTT29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\": cer}"
      ],
      "metadata": {
        "id": "gqMxF2b8T3bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import default_data_collator\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vJAvX80jT7mX",
        "outputId": "3639d921-0d63-4bc6-b4ff-5e474a0a20c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=12.156770706176758, metrics={'train_runtime': 3.3658, 'train_samples_per_second': 0.891, 'train_steps_per_second': 0.891, 'total_flos': 1598481352359936.0, 'train_loss': 12.156770706176758, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./finetune/')"
      ],
      "metadata": {
        "id": "SwRdRx3AUR_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae95029a-b68b-4e61-cc79-ddb02cac6630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in ./finetune/config.json\n",
            "Model weights saved in ./finetune/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests \n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"./finetune/\")\n",
        "#processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "\n",
        "url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\" \n",
        "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
        "#image = Image.open('/content/6.png').convert(\"RGB\")\n",
        "\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values \n",
        "generated_ids = model.generate(pixel_values)\n",
        "\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "rx4tkc3ec_Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "RTUFkPQJec3H",
        "outputId": "4317b086-f916-4b22-a32d-c5f189631aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ak among among among removed removed removed motion motion provides provides provides motion motion motion removed removed Syria Syria Syria removed removed trial trial trial forced forced forcedeteretereter compensation compensation compensation    Republic Republic Republic   compensation compensation college college compensation compensationetereter morning morning morninghalfhalfhalf removed removed Republic Republic motion provides motion'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel\n",
        "from transformers import DeiTModel, DeiTConfig\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# initialize a vit-bert from a pretrained ViT and a pretrained BERT model. Note that the cross-attention layers will be randomly initialized\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"urduhack/roberta-urdu-small\")\n",
        "# saving model after fine-tuning\n",
        "model.save_pretrained(\"./urduhack-bert\")\n",
        "# load fine-tuned model\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"./urduhack-bert\")"
      ],
      "metadata": {
        "id": "4YoNq5TMVCkb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}